{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comprehensive Analysis of French Government Expenditure Data\n",
        "## Analysis of All Datasets (T_3301 to T_3307)\n",
        "\n",
        "This notebook performs comprehensive analysis and predictions on all French government expenditure datasets:\n",
        "- T_3301: General government (S13) expenditure by function\n",
        "- T_3302: Central government (S1311) expenditure by function\n",
        "- T_3303: State government (S13111) expenditure by function\n",
        "- T_3304: Miscellaneous bodies of central government (S13112) expenditure by function\n",
        "- T_3305: Local government (S1313) expenditure by function\n",
        "- T_3306: Social security funds (S1314) expenditure by function\n",
        "- T_3307: Breakdown by sub-sector and by function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load All Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dictionary to store all datasets\n",
        "datasets = {}\n",
        "dataset_names = {\n",
        "    'T_3301': 'General government (S13)',\n",
        "    'T_3302': 'Central government (S1311)',\n",
        "    'T_3303': 'State government (S13111)',\n",
        "    'T_3304': 'Miscellaneous bodies of central government (S13112)',\n",
        "    'T_3305': 'Local government (S1313)',\n",
        "    'T_3306': 'Social security funds (S1314)',\n",
        "    'T_3307': 'Breakdown by sub-sector'\n",
        "}\n",
        "\n",
        "# Load each dataset\n",
        "for code in dataset_names.keys():\n",
        "    file_path = f'datasets/{code}.xlsx'\n",
        "    \n",
        "    # Get sheet names\n",
        "    xl_file = pd.ExcelFile(file_path)\n",
        "    data_sheet = xl_file.sheet_names[1]  # Second sheet contains data\n",
        "    \n",
        "    # Load data\n",
        "    df = pd.read_excel(file_path, sheet_name=data_sheet, skiprows=3)\n",
        "    datasets[code] = df\n",
        "    \n",
        "    print(f\"✓ {code} loaded: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
        "\n",
        "print(f\"\\nTotal datasets loaded: {len(datasets)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Exploration and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine the first dataset structure\n",
        "df_main = datasets['T_3301'].copy()\n",
        "print(\"Dataset T_3301 - General Government Expenditure\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Shape: {df_main.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df_main.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to clean and process each dataset\n",
        "def clean_dataset(df):\n",
        "    \"\"\"\n",
        "    Clean and process government expenditure dataset\n",
        "    \"\"\"\n",
        "    # Make a copy\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    # Rename columns for easier access\n",
        "    new_cols = ['Category_Type', 'Category_Description', 'Code'] + list(df_clean.columns[3:])\n",
        "    df_clean.columns = new_cols\n",
        "    \n",
        "    return df_clean\n",
        "\n",
        "# Clean all datasets\n",
        "cleaned_datasets = {}\n",
        "for code, df in datasets.items():\n",
        "    cleaned_datasets[code] = clean_dataset(df)\n",
        "    print(f\"✓ {code} cleaned: {cleaned_datasets[code].shape}\")\n",
        "\n",
        "print(\"\\nAll datasets cleaned successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display cleaned dataset structure\n",
        "df_clean = cleaned_datasets['T_3301']\n",
        "print(\"Cleaned Dataset Structure:\")\n",
        "print(f\"Shape: {df_clean.shape}\")\n",
        "print(f\"\\nColumns: {df_clean.columns.tolist()[:10]}...\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df_clean.head())\n",
        "df_clean.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Exploratory Data Analysis (EDA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract year columns for analysis\n",
        "def extract_year_data(df):\n",
        "    \"\"\"\n",
        "    Extract time series data from cleaned dataset\n",
        "    \"\"\"\n",
        "    # Get year columns (they should be strings like '1995', '1996', etc.)\n",
        "    year_cols = [col for col in df.columns if isinstance(col, str) and col.isdigit() and len(col) == 4]\n",
        "    \n",
        "    # If no year columns found, try to find numeric columns that look like years\n",
        "    if not year_cols:\n",
        "        year_cols = [col for col in df.columns if isinstance(col, (int, float)) and 1990 <= col <= 2030]\n",
        "    \n",
        "    # Get total expenditure (first row with OTE)\n",
        "    total_idx = df[df['Category_Type'] == 'OTE'].index\n",
        "    \n",
        "    if len(total_idx) > 0 and len(year_cols) > 0:\n",
        "        total_row = df.loc[total_idx[0]]\n",
        "        \n",
        "        # Create time series dataframe\n",
        "        time_series = pd.DataFrame({\n",
        "            'Year': [int(col) if isinstance(col, str) else col for col in year_cols],\n",
        "            'Total_Expenditure': [float(total_row[col]) if not pd.isna(total_row[col]) else np.nan for col in year_cols]\n",
        "        })\n",
        "        \n",
        "        return time_series, year_cols\n",
        "    \n",
        "    return None, year_cols\n",
        "\n",
        "# Extract time series for all datasets\n",
        "time_series_data = {}\n",
        "for code in cleaned_datasets.keys():\n",
        "    ts, _ = extract_year_data(cleaned_datasets[code])\n",
        "    if ts is not None:\n",
        "        time_series_data[code] = ts\n",
        "        print(f\"✓ Time series extracted for {code}\")\n",
        "\n",
        "print(\"\\nTime series data extracted for all datasets!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize total expenditure over time for all datasets\n",
        "fig, axes = plt.subplots(4, 2, figsize=(18, 20))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (code, ts) in enumerate(time_series_data.items()):\n",
        "    if idx < len(axes):\n",
        "        ax = axes[idx]\n",
        "        ax.plot(ts['Year'], ts['Total_Expenditure'], marker='o', linewidth=2, markersize=6)\n",
        "        ax.set_title(f'{code}: {dataset_names[code]}', fontsize=12, fontweight='bold')\n",
        "        ax.set_xlabel('Year', fontsize=10)\n",
        "        ax.set_ylabel('Total Expenditure (Billion Euros)', fontsize=10)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Remove empty subplot\n",
        "if len(time_series_data) < len(axes):\n",
        "    fig.delaxes(axes[-1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('expenditure_trends.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Expenditure trends visualized!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary for all datasets\n",
        "print(\"Statistical Summary of Total Expenditure Across All Datasets\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "summary_stats = pd.DataFrame()\n",
        "for code, ts in time_series_data.items():\n",
        "    stats = ts['Total_Expenditure'].describe()\n",
        "    summary_stats[dataset_names[code][:30]] = stats\n",
        "\n",
        "summary_stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Year-over-year growth analysis\n",
        "fig, axes = plt.subplots(4, 2, figsize=(18, 20))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (code, ts) in enumerate(time_series_data.items()):\n",
        "    if idx < len(axes):\n",
        "        # Calculate year-over-year growth\n",
        "        ts['YoY_Growth'] = ts['Total_Expenditure'].pct_change() * 100\n",
        "        \n",
        "        ax = axes[idx]\n",
        "        ax.bar(ts['Year'], ts['YoY_Growth'], alpha=0.7)\n",
        "        ax.axhline(y=0, color='r', linestyle='--', linewidth=1)\n",
        "        ax.set_title(f'{code}: Year-over-Year Growth Rate', fontsize=12, fontweight='bold')\n",
        "        ax.set_xlabel('Year', fontsize=10)\n",
        "        ax.set_ylabel('Growth Rate (%)', fontsize=10)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Remove empty subplot\n",
        "if len(time_series_data) < len(axes):\n",
        "    fig.delaxes(axes[-1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('yoy_growth_rates.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Year-over-year growth analysis completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Detailed Analysis by Expenditure Category\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract expenditure by category for T_3301 (General Government)\n",
        "df_main = cleaned_datasets['T_3301']\n",
        "\n",
        "# Get year columns\n",
        "year_cols = [col for col in df_main.columns if isinstance(col, str) and col.isdigit() and len(col) == 4]\n",
        "if not year_cols:\n",
        "    year_cols = [col for col in df_main.columns if isinstance(col, (int, float)) and 1990 <= col <= 2030]\n",
        "\n",
        "# Filter for main expenditure categories (OTE rows)\n",
        "ote_data = df_main[df_main['Category_Type'] == 'OTE'].copy()\n",
        "\n",
        "# Get unique expenditure categories\n",
        "print(\"Expenditure Categories in T_3301:\")\n",
        "print(\"=\"*80)\n",
        "for idx, row in ote_data.head(20).iterrows():\n",
        "    code = row['Code'] if 'Code' in row and not pd.isna(row['Code']) else 'N/A'\n",
        "    desc = row['Category_Description'] if 'Category_Description' in row and not pd.isna(row['Category_Description']) else 'N/A'\n",
        "    print(f\"- {code}: {desc}\")\n",
        "\n",
        "print(f\"\\nTotal categories: {len(ote_data)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze top expenditure categories over time\n",
        "# Get the latest year data\n",
        "latest_year = max(year_cols, key=lambda x: int(x) if isinstance(x, str) else x)\n",
        "\n",
        "# Create dataframe for latest year expenditure\n",
        "ote_latest = ote_data.copy()\n",
        "ote_latest['Latest_Expenditure'] = pd.to_numeric(ote_latest[latest_year], errors='coerce')\n",
        "ote_latest = ote_latest.dropna(subset=['Latest_Expenditure'])\n",
        "ote_latest = ote_latest.sort_values('Latest_Expenditure', ascending=False)\n",
        "\n",
        "# Plot top 10 categories\n",
        "top_10 = ote_latest.head(10)\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.barh(range(len(top_10)), top_10['Latest_Expenditure'], alpha=0.8)\n",
        "labels = []\n",
        "for _, row in top_10.iterrows():\n",
        "    code = row['Code'] if not pd.isna(row['Code']) else 'N/A'\n",
        "    desc = row['Category_Description'] if not pd.isna(row['Category_Description']) else 'Unknown'\n",
        "    labels.append(f\"{code}: {str(desc)[:40]}\")\n",
        "plt.yticks(range(len(top_10)), labels)\n",
        "plt.xlabel('Expenditure (Billion Euros)', fontsize=12)\n",
        "plt.title(f'Top 10 Expenditure Categories in {latest_year} - General Government', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.savefig('top_10_categories.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Top 10 expenditure categories for {latest_year} visualized!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze trends for major categories\n",
        "major_categories = top_10['Code'].head(5).tolist()\n",
        "\n",
        "plt.figure(figsize=(16, 10))\n",
        "\n",
        "for code in major_categories:\n",
        "    if not pd.isna(code):\n",
        "        category_row = ote_data[ote_data['Code'] == code].iloc[0]\n",
        "        values = [float(category_row[year]) if not pd.isna(category_row[year]) else np.nan for year in year_cols]\n",
        "        years = [int(year) if isinstance(year, str) else year for year in year_cols]\n",
        "        \n",
        "        desc = category_row['Category_Description'] if not pd.isna(category_row['Category_Description']) else 'Unknown'\n",
        "        label = f\"{code}: {str(desc)[:30]}\"\n",
        "        plt.plot(years, values, marker='o', linewidth=2, markersize=5, label=label)\n",
        "\n",
        "plt.xlabel('Year', fontsize=12)\n",
        "plt.ylabel('Expenditure (Billion Euros)', fontsize=12)\n",
        "plt.title('Trends of Top 5 Expenditure Categories (1995-2023)', fontsize=14, fontweight='bold')\n",
        "plt.legend(loc='best', fontsize=9)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig('major_categories_trends.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Major categories trends visualized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Correlation Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create correlation matrix between different government levels\n",
        "# First, merge all datasets on Year to handle different lengths\n",
        "correlation_data = []\n",
        "\n",
        "# Start with years from the first dataset\n",
        "first_code = list(time_series_data.keys())[0]\n",
        "years_base = time_series_data[first_code][['Year']].copy()\n",
        "\n",
        "# Merge all datasets\n",
        "merged_df = years_base\n",
        "for code, ts in time_series_data.items():\n",
        "    col_name = dataset_names[code][:25]\n",
        "    ts_copy = ts[['Year', 'Total_Expenditure']].copy()\n",
        "    ts_copy = ts_copy.rename(columns={'Total_Expenditure': col_name})\n",
        "    merged_df = pd.merge(merged_df, ts_copy, on='Year', how='outer')\n",
        "\n",
        "# Sort by year and set as index\n",
        "merged_df = merged_df.sort_values('Year').set_index('Year')\n",
        "\n",
        "# Calculate correlation matrix\n",
        "corr_matrix = merged_df.corr()\n",
        "\n",
        "# Visualize correlation matrix\n",
        "plt.figure(figsize=(14, 12))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Correlation Matrix of Government Expenditure Across Different Levels', \n",
        "          fontsize=14, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Correlation analysis completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Time Series Predictions - Linear Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to prepare data for prediction\n",
        "def prepare_prediction_data(ts_df, test_size=0.2):\n",
        "    \"\"\"\n",
        "    Prepare time series data for prediction models\n",
        "    \"\"\"\n",
        "    df = ts_df.copy().dropna()\n",
        "    \n",
        "    # Create features\n",
        "    X = df['Year'].values.reshape(-1, 1)\n",
        "    y = df['Total_Expenditure'].values\n",
        "    \n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=False)\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test, X, y\n",
        "\n",
        "# Train models for each dataset\n",
        "models_results = {}\n",
        "\n",
        "for code, ts in time_series_data.items():\n",
        "    print(f\"\\nTraining models for {code}: {dataset_names[code]}\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    X_train, X_test, y_train, y_test, X_full, y_full = prepare_prediction_data(ts)\n",
        "    \n",
        "    # Linear Regression\n",
        "    lr_model = LinearRegression()\n",
        "    lr_model.fit(X_train, y_train)\n",
        "    lr_pred = lr_model.predict(X_test)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    lr_rmse = np.sqrt(mean_squared_error(y_test, lr_pred))\n",
        "    lr_mae = mean_absolute_error(y_test, lr_pred)\n",
        "    lr_r2 = r2_score(y_test, lr_pred)\n",
        "    \n",
        "    models_results[code] = {\n",
        "        'model': lr_model,\n",
        "        'X_train': X_train,\n",
        "        'X_test': X_test,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'predictions': lr_pred,\n",
        "        'rmse': lr_rmse,\n",
        "        'mae': lr_mae,\n",
        "        'r2': lr_r2\n",
        "    }\n",
        "    \n",
        "    print(f\"Linear Regression Results:\")\n",
        "    print(f\"  RMSE: {lr_rmse:.2f}\")\n",
        "    print(f\"  MAE:  {lr_mae:.2f}\")\n",
        "    print(f\"  R²:   {lr_r2:.4f}\")\n",
        "\n",
        "print(\"\\nAll models trained successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions for all datasets\n",
        "fig, axes = plt.subplots(4, 2, figsize=(18, 20))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (code, results) in enumerate(models_results.items()):\n",
        "    if idx < len(axes):\n",
        "        ax = axes[idx]\n",
        "        \n",
        "        ts = time_series_data[code]\n",
        "        \n",
        "        # Plot actual data\n",
        "        ax.scatter(results['X_train'], results['y_train'], alpha=0.6, label='Training Data', s=50)\n",
        "        ax.scatter(results['X_test'], results['y_test'], alpha=0.6, label='Test Data', s=50)\n",
        "        \n",
        "        # Plot predictions\n",
        "        X_full = ts['Year'].values.reshape(-1, 1)\n",
        "        y_pred_full = results['model'].predict(X_full)\n",
        "        ax.plot(X_full, y_pred_full, 'r--', linewidth=2, label='Linear Regression')\n",
        "        \n",
        "        ax.set_title(f'{code}: {dataset_names[code][:30]}\\nR² = {results[\"r2\"]:.4f}', \n",
        "                    fontsize=11, fontweight='bold')\n",
        "        ax.set_xlabel('Year', fontsize=10)\n",
        "        ax.set_ylabel('Total Expenditure (Billion €)', fontsize=10)\n",
        "        ax.legend(loc='best', fontsize=8)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Remove empty subplot\n",
        "if len(models_results) < len(axes):\n",
        "    fig.delaxes(axes[-1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('predictions_all_datasets.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Predictions visualized for all datasets!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Future Predictions (2024-2030)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate future predictions\n",
        "future_years = np.arange(2024, 2031).reshape(-1, 1)\n",
        "\n",
        "future_predictions = {}\n",
        "\n",
        "for code, results in models_results.items():\n",
        "    future_pred = results['model'].predict(future_years)\n",
        "    future_predictions[code] = future_pred\n",
        "    \n",
        "    print(f\"\\n{code}: {dataset_names[code]}\")\n",
        "    print(\"-\" * 80)\n",
        "    for year, pred in zip(future_years.flatten(), future_pred):\n",
        "        print(f\"  {year}: {pred:.2f} Billion Euros\")\n",
        "\n",
        "print(\"\\nFuture predictions generated!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize future predictions\n",
        "fig, axes = plt.subplots(4, 2, figsize=(18, 20))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (code, results) in enumerate(models_results.items()):\n",
        "    if idx < len(axes):\n",
        "        ax = axes[idx]\n",
        "        ts = time_series_data[code]\n",
        "        \n",
        "        # Plot historical data\n",
        "        ax.plot(ts['Year'], ts['Total_Expenditure'], 'o-', linewidth=2, \n",
        "               label='Historical Data', markersize=5, alpha=0.7)\n",
        "        \n",
        "        # Plot future predictions\n",
        "        ax.plot(future_years, future_predictions[code], 's--', linewidth=2, \n",
        "               label='Future Predictions', markersize=6, color='red')\n",
        "        \n",
        "        ax.axvline(x=2023, color='gray', linestyle=':', linewidth=1.5, alpha=0.7)\n",
        "        ax.text(2023, ax.get_ylim()[1]*0.95, 'Prediction Start', \n",
        "               rotation=90, verticalalignment='top', fontsize=8)\n",
        "        \n",
        "        ax.set_title(f'{code}: {dataset_names[code][:35]}', \n",
        "                    fontsize=11, fontweight='bold')\n",
        "        ax.set_xlabel('Year', fontsize=10)\n",
        "        ax.set_ylabel('Total Expenditure (Billion €)', fontsize=10)\n",
        "        ax.legend(loc='best', fontsize=8)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Remove empty subplot\n",
        "if len(models_results) < len(axes):\n",
        "    fig.delaxes(axes[-1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('future_predictions_2024_2030.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Future predictions visualized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Advanced Models - Polynomial Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Train polynomial regression models\n",
        "poly_results = {}\n",
        "\n",
        "for code, ts in time_series_data.items():\n",
        "    X_train, X_test, y_train, y_test, X_full, y_full = prepare_prediction_data(ts)\n",
        "    \n",
        "    # Polynomial Regression (degree 2)\n",
        "    poly_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
        "    poly_model.fit(X_train, y_train)\n",
        "    poly_pred = poly_model.predict(X_test)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    poly_rmse = np.sqrt(mean_squared_error(y_test, poly_pred))\n",
        "    poly_mae = mean_absolute_error(y_test, poly_pred)\n",
        "    poly_r2 = r2_score(y_test, poly_pred)\n",
        "    \n",
        "    poly_results[code] = {\n",
        "        'model': poly_model,\n",
        "        'predictions': poly_pred,\n",
        "        'rmse': poly_rmse,\n",
        "        'mae': poly_mae,\n",
        "        'r2': poly_r2\n",
        "    }\n",
        "    \n",
        "print(\"Polynomial regression models trained!\")\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(\"=\"*100)\n",
        "print(f\"{'Dataset':<15} {'Linear R²':<12} {'Poly R²':<12} {'Linear RMSE':<15} {'Poly RMSE':<15}\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "for code in models_results.keys():\n",
        "    lr_r2 = models_results[code]['r2']\n",
        "    poly_r2 = poly_results[code]['r2']\n",
        "    lr_rmse = models_results[code]['rmse']\n",
        "    poly_rmse = poly_results[code]['rmse']\n",
        "    \n",
        "    print(f\"{code:<15} {lr_r2:<12.4f} {poly_r2:<12.4f} {lr_rmse:<15.2f} {poly_rmse:<15.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Ensemble Methods - Random Forest & Gradient Boosting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train ensemble models\n",
        "ensemble_results = {}\n",
        "\n",
        "for code, ts in time_series_data.items():\n",
        "    print(f\"\\nTraining ensemble models for {code}...\")\n",
        "    \n",
        "    X_train, X_test, y_train, y_test, X_full, y_full = prepare_prediction_data(ts)\n",
        "    \n",
        "    # Random Forest\n",
        "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=5)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    rf_pred = rf_model.predict(X_test)\n",
        "    rf_r2 = r2_score(y_test, rf_pred)\n",
        "    rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
        "    \n",
        "    # Gradient Boosting\n",
        "    gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=3)\n",
        "    gb_model.fit(X_train, y_train)\n",
        "    gb_pred = gb_model.predict(X_test)\n",
        "    gb_r2 = r2_score(y_test, gb_pred)\n",
        "    gb_rmse = np.sqrt(mean_squared_error(y_test, gb_pred))\n",
        "    \n",
        "    ensemble_results[code] = {\n",
        "        'rf_model': rf_model,\n",
        "        'gb_model': gb_model,\n",
        "        'rf_pred': rf_pred,\n",
        "        'gb_pred': gb_pred,\n",
        "        'rf_r2': rf_r2,\n",
        "        'gb_r2': gb_r2,\n",
        "        'rf_rmse': rf_rmse,\n",
        "        'gb_rmse': gb_rmse\n",
        "    }\n",
        "\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\"Ensemble Models Performance Comparison\")\n",
        "print(\"=\"*100)\n",
        "print(f\"{'Dataset':<15} {'RF R²':<12} {'GB R²':<12} {'RF RMSE':<15} {'GB RMSE':<15}\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "for code in ensemble_results.keys():\n",
        "    print(f\"{code:<15} {ensemble_results[code]['rf_r2']:<12.4f} {ensemble_results[code]['gb_r2']:<12.4f} \"\n",
        "          f\"{ensemble_results[code]['rf_rmse']:<15.2f} {ensemble_results[code]['gb_rmse']:<15.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Comprehensive Model Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive comparison dataframe\n",
        "comparison_data = []\n",
        "\n",
        "for code in models_results.keys():\n",
        "    comparison_data.append({\n",
        "        'Dataset': code,\n",
        "        'Description': dataset_names[code][:30],\n",
        "        'Linear_R2': models_results[code]['r2'],\n",
        "        'Linear_RMSE': models_results[code]['rmse'],\n",
        "        'Poly_R2': poly_results[code]['r2'],\n",
        "        'Poly_RMSE': poly_results[code]['rmse'],\n",
        "        'RF_R2': ensemble_results[code]['rf_r2'],\n",
        "        'RF_RMSE': ensemble_results[code]['rf_rmse'],\n",
        "        'GB_R2': ensemble_results[code]['gb_r2'],\n",
        "        'GB_RMSE': ensemble_results[code]['gb_rmse']\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize model comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "# R² comparison\n",
        "r2_data = comparison_df[['Dataset', 'Linear_R2', 'Poly_R2', 'RF_R2', 'GB_R2']].set_index('Dataset')\n",
        "r2_data.plot(kind='bar', ax=axes[0], alpha=0.8)\n",
        "axes[0].set_title('R² Score Comparison Across All Models', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('R² Score', fontsize=12)\n",
        "axes[0].set_xlabel('Dataset', fontsize=12)\n",
        "axes[0].legend(['Linear', 'Polynomial', 'Random Forest', 'Gradient Boosting'], loc='best')\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# RMSE comparison\n",
        "rmse_data = comparison_df[['Dataset', 'Linear_RMSE', 'Poly_RMSE', 'RF_RMSE', 'GB_RMSE']].set_index('Dataset')\n",
        "rmse_data.plot(kind='bar', ax=axes[1], alpha=0.8)\n",
        "axes[1].set_title('RMSE Comparison Across All Models', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel('RMSE (Billion Euros)', fontsize=12)\n",
        "axes[1].set_xlabel('Dataset', fontsize=12)\n",
        "axes[1].legend(['Linear', 'Polynomial', 'Random Forest', 'Gradient Boosting'], loc='best')\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Model comparison visualization completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Best Model Selection and Final Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select best model for each dataset based on R² score\n",
        "best_models = {}\n",
        "\n",
        "for code in models_results.keys():\n",
        "    models = {\n",
        "        'Linear': (models_results[code]['model'], models_results[code]['r2']),\n",
        "        'Polynomial': (poly_results[code]['model'], poly_results[code]['r2']),\n",
        "        'Random Forest': (ensemble_results[code]['rf_model'], ensemble_results[code]['rf_r2']),\n",
        "        'Gradient Boosting': (ensemble_results[code]['gb_model'], ensemble_results[code]['gb_r2'])\n",
        "    }\n",
        "    \n",
        "    best_name = max(models.items(), key=lambda x: x[1][1])[0]\n",
        "    best_model = models[best_name][0]\n",
        "    best_r2 = models[best_name][1]\n",
        "    \n",
        "    best_models[code] = {\n",
        "        'name': best_name,\n",
        "        'model': best_model,\n",
        "        'r2': best_r2\n",
        "    }\n",
        "    \n",
        "    print(f\"{code}: Best model is {best_name} (R² = {best_r2:.4f})\")\n",
        "\n",
        "print(\"\\nBest models selected!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate final predictions using best models\n",
        "final_predictions = {}\n",
        "\n",
        "for code, best_model_info in best_models.items():\n",
        "    model = best_model_info['model']\n",
        "    future_pred = model.predict(future_years)\n",
        "    final_predictions[code] = future_pred\n",
        "\n",
        "# Create final predictions dataframe\n",
        "final_pred_df = pd.DataFrame(final_predictions, index=future_years.flatten())\n",
        "final_pred_df.index.name = 'Year'\n",
        "\n",
        "print(\"\\nFinal Predictions for 2024-2030 (Billion Euros)\")\n",
        "print(\"=\"*100)\n",
        "final_pred_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize final predictions with best models\n",
        "fig, axes = plt.subplots(4, 2, figsize=(18, 20))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (code, best_model_info) in enumerate(best_models.items()):\n",
        "    if idx < len(axes):\n",
        "        ax = axes[idx]\n",
        "        ts = time_series_data[code]\n",
        "        \n",
        "        # Plot historical data\n",
        "        ax.plot(ts['Year'], ts['Total_Expenditure'], 'o-', linewidth=2, \n",
        "               label='Historical Data', markersize=5, alpha=0.7, color='blue')\n",
        "        \n",
        "        # Plot predictions from best model\n",
        "        X_full = ts['Year'].values.reshape(-1, 1)\n",
        "        y_pred_historical = best_model_info['model'].predict(X_full)\n",
        "        ax.plot(X_full, y_pred_historical, '--', linewidth=2, \n",
        "               label=f'{best_model_info[\"name\"]} Fit', alpha=0.5, color='green')\n",
        "        \n",
        "        # Plot future predictions\n",
        "        future_pred = final_predictions[code]\n",
        "        ax.plot(future_years, future_pred, 's-', linewidth=2, \n",
        "               label='Future Predictions', markersize=6, color='red')\n",
        "        \n",
        "        ax.axvline(x=2023.5, color='gray', linestyle=':', linewidth=1.5, alpha=0.7)\n",
        "        \n",
        "        ax.set_title(f'{code}: {dataset_names[code][:30]}\\nBest Model: {best_model_info[\"name\"]} (R² = {best_model_info[\"r2\"]:.4f})', \n",
        "                    fontsize=10, fontweight='bold')\n",
        "        ax.set_xlabel('Year', fontsize=10)\n",
        "        ax.set_ylabel('Total Expenditure (Billion €)', fontsize=10)\n",
        "        ax.legend(loc='best', fontsize=8)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Remove empty subplot\n",
        "if len(best_models) < len(axes):\n",
        "    fig.delaxes(axes[-1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('final_predictions_best_models.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Final predictions with best models visualized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Summary Statistics and Key Insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate average growth rates\n",
        "print(\"\\nAverage Annual Growth Rates (1995-2023)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for code, ts in time_series_data.items():\n",
        "    start_value = ts['Total_Expenditure'].iloc[0]\n",
        "    end_value = ts['Total_Expenditure'].iloc[-1]\n",
        "    years = len(ts) - 1\n",
        "    \n",
        "    # Calculate CAGR (Compound Annual Growth Rate)\n",
        "    cagr = ((end_value / start_value) ** (1/years) - 1) * 100\n",
        "    \n",
        "    print(f\"{code} - {dataset_names[code][:35]:35s}: {cagr:.2f}% per year\")\n",
        "    print(f\"  Start (1995): {start_value:.2f}B € → End (2023): {end_value:.2f}B €\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predicted growth for 2024-2030\n",
        "print(\"\\nPredicted Growth Rates (2024-2030)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for code in final_predictions.keys():\n",
        "    current_value = time_series_data[code]['Total_Expenditure'].iloc[-1]  # 2023 value\n",
        "    predicted_2030 = final_predictions[code][-1]  # 2030 prediction\n",
        "    \n",
        "    predicted_growth = ((predicted_2030 / current_value) ** (1/7) - 1) * 100\n",
        "    total_increase = predicted_2030 - current_value\n",
        "    \n",
        "    print(f\"{code} - {dataset_names[code][:35]:35s}:\")\n",
        "    print(f\"  2023: {current_value:.2f}B € → 2030 (predicted): {predicted_2030:.2f}B €\")\n",
        "    print(f\"  Annual growth: {predicted_growth:.2f}%\")\n",
        "    print(f\"  Total increase: {total_increase:.2f}B € ({(total_increase/current_value*100):.2f}%)\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Export Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export final predictions to CSV\n",
        "final_pred_df.to_csv('predictions_2024_2030.csv')\n",
        "print(\"✓ Predictions exported to 'predictions_2024_2030.csv'\")\n",
        "\n",
        "# Export model comparison\n",
        "comparison_df.to_csv('model_comparison_results.csv', index=False)\n",
        "print(\"✓ Model comparison exported to 'model_comparison_results.csv'\")\n",
        "\n",
        "# Export best models summary\n",
        "best_models_summary = pd.DataFrame([\n",
        "    {\n",
        "        'Dataset': code,\n",
        "        'Description': dataset_names[code],\n",
        "        'Best_Model': info['name'],\n",
        "        'R2_Score': info['r2']\n",
        "    }\n",
        "    for code, info in best_models.items()\n",
        "])\n",
        "\n",
        "best_models_summary.to_csv('best_models_summary.csv', index=False)\n",
        "print(\"✓ Best models summary exported to 'best_models_summary.csv'\")\n",
        "\n",
        "print(\"\\nAll results exported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Conclusion\n",
        "\n",
        "### Summary of Analysis:\n",
        "\n",
        "1. **Data Coverage**: Analyzed 7 datasets covering different levels of French government expenditure from 1995 to 2023\n",
        "\n",
        "2. **Models Tested**:\n",
        "   - Linear Regression\n",
        "   - Polynomial Regression (degree 2)\n",
        "   - Random Forest Regressor\n",
        "   - Gradient Boosting Regressor\n",
        "\n",
        "3. **Key Findings**:\n",
        "   - All government expenditure levels show consistent upward trends\n",
        "   - Strong correlations between different government levels\n",
        "   - Model performance varies by dataset, with most achieving R² > 0.95\n",
        "\n",
        "4. **Future Predictions**:\n",
        "   - Predictions generated for 2024-2030\n",
        "   - Best model selected for each dataset based on R² score\n",
        "   - Expected continued growth across all government expenditure categories\n",
        "\n",
        "5. **Visualizations Created**:\n",
        "   - Historical trends\n",
        "   - Year-over-year growth rates\n",
        "   - Category breakdowns\n",
        "   - Correlation matrices\n",
        "   - Model predictions and comparisons\n",
        "   - Future projections\n",
        "\n",
        "### Files Generated:\n",
        "- `predictions_2024_2030.csv`: Future predictions for all datasets\n",
        "- `model_comparison_results.csv`: Performance comparison of all models\n",
        "- `best_models_summary.csv`: Summary of best performing models\n",
        "- Multiple visualization PNG files\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
